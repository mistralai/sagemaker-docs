{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39357e72",
   "metadata": {},
   "source": [
    "# Tutorial: Deploying and Using Mistral AI Models on Amazon SageMaker\n",
    "\n",
    "In this tutorial, you will learn how to deploy and use Mistral AI models on Amazon SageMaker. We will walk you through the steps of deploying a model, creating an endpoint, and invoking the endpoint for inference.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Ensure you have an active AWS account and the necessary permissions to use Amazon SageMaker.\n",
    "- Install the AWS SDK for Python (Boto3) and the Amazon SageMaker Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2d9dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role, ModelPackage\n",
    "\n",
    "# Common variables\n",
    "session = sage.Session()\n",
    "role = get_execution_role()\n",
    "sm_runtime = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33656162",
   "metadata": {},
   "source": [
    "## Step 1: Define Model Package ARN and Endpoint Configuration\n",
    "\n",
    "First, define the ARN (Amazon Resource Name) for the Mistral AI model package you want to deploy. Also, specify the desired endpoint name and the instance type for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "091827ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PACKAGE_ARN = \"arn:aws:sagemaker:...\" # Replace with mistral-large arn for example\n",
    "ENDPOINT_NAME = \"mistral-large\"\n",
    "INSTANCE_TYPE = \"ml.p5.48xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa3b006",
   "metadata": {},
   "source": [
    "## Step 2: Create a Model Package Object\n",
    "\n",
    "Next, create a `ModelPackage` object using the Amazon SageMaker Python SDK. This object will be used to deploy the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f393fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelPackage(\n",
    "    role=role,\n",
    "    model_package_arn=MODEL_PACKAGE_ARN,\n",
    "    sagemaker_session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c7a886",
   "metadata": {},
   "source": [
    "## Step 3: Deploy the Model\n",
    "\n",
    "Now, deploy the model to the specified endpoint using the `deploy()` method. Make sure to configure the initial instance count, instance type, and timeouts according to your requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0381cf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------!"
     ]
    }
   ],
   "source": [
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=INSTANCE_TYPE,\n",
    "    endpoint_name=ENDPOINT_NAME,\n",
    "    model_data_download_timeout=3600,\n",
    "    container_startup_health_check_timeout=3600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be4c7b",
   "metadata": {},
   "source": [
    "## Step 4: Prepare the Request Body\n",
    "\n",
    "Create a request body containing the necessary information for invoking the Mistral AI model. Refer to the [Mistral AI API documentation](https://docs.mistral.ai/api/) for more details on available parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33fcb31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_body = {\n",
    "    \"model\": \"mistral\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Who is the most renowned French painter?\"}],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f7ee2e",
   "metadata": {},
   "source": [
    "## Step 5: Invoke the Endpoint\n",
    "\n",
    "Invoke the deployed endpoint using the Amazon SageMaker Runtime `invoke_endpoint()` method. Pass the endpoint name, content type, and the request body as JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "633bbd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=model.endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=json.dumps(request_body))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb8a9bf",
   "metadata": {},
   "source": [
    "## Step 6: Process the Response\n",
    "\n",
    "Decode the response body and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b7ea378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "response_body = response[\"Body\"].read().decode()\n",
    "print(response_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00139765",
   "metadata": {},
   "source": [
    "That's it! You have successfully deployed and invoked a Mistral AI model on Amazon SageMaker. You can now use this setup to perform inference with Mistral AI models in your applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
